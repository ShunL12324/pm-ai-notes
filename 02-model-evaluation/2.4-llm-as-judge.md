# 2.4 LLM-as-Judge 方法论

使用大模型作为评估者，评判其他模型或自身的输出质量。

## 核心概念

### 什么是 LLM-as-Judge
- 用强大的 LLM（如 GPT-4）作为"裁判"
- 评估其他模型生成内容的质量
- 适用于没有标准答案的开放式任务

### 优势
- **成本低**：相比人工标注便宜很多
- **可扩展**：可以快速评估大量样本
- **一致性**：减少人工标注的主观差异
- **适合主观任务**：创意写作、对话质量等

## 主要偏差问题

### 位置偏差 (Position Bias)
- **现象**：倾向于选择特定位置的答案
- **例子**：A/B 对比时总是偏好第一个
- **缓解**：交换位置多次评估取平均

### 冗长偏差 (Verbosity Bias)
- **现象**：倾向于认为更长的回答更好
- **本质**：长度 ≠ 质量
- **缓解**：明确评估标准，控制长度因素

### 自我偏好 (Self-Enhancement Bias)
- **现象**：模型偏好自己生成的内容
- **影响**：用 GPT-4 评估时可能偏向 GPT-4
- **缓解**：使用不同模型交叉评估

## 改进策略

### 多评委投票
- 使用多个不同模型评估
- 投票或加权平均得出结论
- 减少单一模型的偏差

### 位置交换验证
- A vs B 和 B vs A 都评一次
- 结果一致才算有效
- 过滤掉位置敏感的判断

### Calibration（校准）
- 用人工标注的数据校准模型评分
- 建立评分与人类判断的映射
- 定期检验一致性

### 结构化评分
- 多维度分别打分（准确性、流畅性、相关性）
- 要求输出评分理由
- 比单一分数更可解释
