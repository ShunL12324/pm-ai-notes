# 2.5 评测框架

主流的 LLM 评测工具和平台。

## lm-evaluation-harness

- **开发者**：EleutherAI
- **地位**：最广泛使用的开源框架
- **特点**：
  - 支持 200+ 评测任务
  - 支持多种模型格式（HuggingFace、vLLM 等）
  - 易于扩展新任务
- **使用场景**：模型开发者、研究者
- **链接**：github.com/EleutherAI/lm-evaluation-harness

## OpenCompass

- **开发者**：上海 AI Lab
- **地位**：国内主流评测框架
- **特点**：
  - 中英文任务覆盖全面
  - 对国产模型支持好
  - 提供在线排行榜
- **使用场景**：国产模型评测
- **链接**：opencompass.org.cn

## HELM (Holistic Evaluation of Language Models)

- **开发者**：Stanford
- **特点**：
  - 强调全面性（Holistic）
  - 多维度评估（准确性、公平性、效率等）
  - 标准化的评测协议
- **使用场景**：学术研究、全面评估
- **链接**：crfm.stanford.edu/helm

## Ragas

- **定位**：专注 RAG 系统评测
- **评估维度**：
  - 上下文相关性
  - 答案准确性
  - 忠实度（是否基于检索内容）
- **使用场景**：RAG 应用开发
- **特点**：可集成到 CI/CD 流程

## 框架选择建议

| 场景 | 推荐框架 |
|------|----------|
| 通用模型评测 | lm-evaluation-harness |
| 国产模型 | OpenCompass |
| 学术研究 | HELM |
| RAG 系统 | Ragas |
